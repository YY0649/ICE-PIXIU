<h2>This is the folder for the summarization task. </h2>

<h3>Basics</h3>

We have used **REALSumm**, **SummEval**, **Newsroom**, **Rank19**,**QAGS_CNN** and **QAGS_XSUM** datasets for our experiments. For each dataset, we converted the original dataset into an unified form as shown below (all texts tokenized, normal cased). The unified data form is in each dataset folder, and is named as `data.pkl`. Note that there is another file `final_p.pkl` in each dataset folder, which is our calculated score file.

```json
{
    "doc_id": {
        "src": "This is the source text.",
        "ref_summ": "This is the reference summary",
        "sys_summs": {
            "sys_name1": {
                "sys_summ": "This is the system summary.",
                "scores": {
                    "human_metric1": 0.3,
                    "human_metric2": 0.5
                }
            }
        }
    }
}
```
For factuality dataset, the `ref_summ` field is the same as the `src` field. For SummEval dataset, there are multiple references, we have added a field called `ref_summs` as shown below. We take the average when combining multi-reference results.

```json
"ref_summs": [
    "This is the first reference summary.",
    "This is the second reference summary.",
    "..."
]
```
After calculating scores using automatic metrics, the `scores` field for each document is updated, like the one below.
```json
"scores": {
    "auto_metric1": 0.9,
    "auto_metric2": 0.7,
    "human_metric1": 0.3,
    "human_metric2": 0.5
}
```


<h3>Setups</h3>

Please run the following commands to download the PRISM model. 

```bash
mkdir models
sh download.sh
```

Our trained BARTScore (on ParaBank2) can be downloaded [here](https://drive.google.com/file/d/1_7JfF7KOInb7ZrxKHIigTMR4ChVET01m/view?usp=sharing). Please also move it to the `models` folder for subsequent experiments if you consider using it.



<h3>Run scores</h3>

Run the following to see all the arguments that are supported by the `score.py` script.

```bash
python score.py --help
```


To reproduce the results for a single reference dataset (all datasets except SummEval), run the following as an example.
```bash
python score.py --file REALSumm/data.pkl --device cuda:0 --output REALSumm/scores.pkl --bert_score --mover_score --rouge --bart_score --bart_score_cnn --prism --prompt bart_cnn_src
```

For SummEval dataset, please add the `--multi_ref` argument.

